{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for better plots\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 1567 linhas/exemplos e 590 colunas/variáveis.\n",
      "A classe majoritária possui 1463 exemplos e a minoritária 104.\n"
     ]
    }
   ],
   "source": [
    "secom = pd.read_table('secom.data', header=None, delim_whitespace=True)\n",
    "Y = pd.read_table('secom_labels.data', header=None, usecols=[0], squeeze=True, delim_whitespace=True)\n",
    "\n",
    "print('Temos {} linhas/exemplos e {} colunas/variáveis.'\\\n",
    "      .format(secom.shape[0], secom.shape[1]))\n",
    "print('A classe majoritária possui {} exemplos e a minoritária {}.'\\\n",
    "      .format(Y[Y == -1].size, Y[Y == 1].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dados representados com numpy array\n",
    "X = secom.as_matrix(columns=None)\n",
    "labels = Y.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessamento\n",
    "### Substitua os dados faltantes pela media da coluna (imputação pela média)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1567, 590)\n"
     ]
    }
   ],
   "source": [
    "# calculando a média das colunas\n",
    "col_mean = stats.nanmean(X, axis=0)\n",
    "\n",
    "#ind obtém os índices onde a coluna possui dados faltantes\n",
    "ind = np.where(np.isnan(X))\n",
    "\n",
    "# substitui os índices faltantes pela média da coluna\n",
    "X[ind] = np.take(col_mean, ind[1])\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz teste com colunas nan:\n",
      " [[  1.   2.  nan]\n",
      " [ nan   3.  nan]\n",
      " [  3.  nan   5.]]\n",
      "\n",
      "A média da 1 coluna é: 2.0\n",
      "A média da 2 coluna é: 2.5\n",
      "A média da 3 coluna é: 5.0\n",
      "\n",
      "Matriz substituída com as médias:\n",
      " [[ 1.   2.   5. ]\n",
      " [ 2.   3.   5. ]\n",
      " [ 3.   2.5  5. ]]\n"
     ]
    }
   ],
   "source": [
    "### Mini teste com uma matriz pequena para visualizar se estou fazendo a substituição das colunas pela média\n",
    "\n",
    "import scipy.stats as stats\n",
    "A = np.array([[1.0     , 2.0, np.nan],\n",
    "             [np.nan, 3.0, np.nan],\n",
    "             [3.0     , np.nan, 5.0]])\n",
    "print('Matriz teste com colunas nan:\\n', A)\n",
    "col_mean = stats.nanmean(A, axis=0)\n",
    "print()\n",
    "for i in range(3):\n",
    "    print('A média da %d coluna é: %s'% (i+1,col_mean[i]))\n",
    "\n",
    "inds = np.where(np.isnan(A))\n",
    "A[inds] = np.take(col_mean, inds[1])\n",
    "print('\\nMatriz substituída com as médias:\\n', A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente padronize as colunas para media 0 e desvio padrao 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale() fornece média zero das colunas e desvio padrão = 1\n",
    "std_secom = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PCA\n",
    "\n",
    "### Vamos encontrar 80% da variância e transformar os Dados. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# função PCA com sklearn\n",
    "def doPCA(x): # x é o argumento do número de componentes do PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=x)\n",
    "    pca.fit(std_secom)\n",
    "    return pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# executando o PCA com 590 componentes.\n",
    "pca = doPCA(std_secom.shape[1]) \n",
    "\n",
    "# os elementos em _var contém a total variância.\n",
    "_var = pca.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# armazena a variância.\n",
    "requested_var = 0\n",
    "\n",
    "# 80%  é a variância requisitada.\n",
    "lim = 0.80\n",
    "\n",
    "# iterações para encontrar a quantidade de dimensões que mantém\n",
    "# 80% da variância\n",
    "for i in range (len(_var)):\n",
    "    requested_var += _var[i]\n",
    "    if requested_var >= lim:\n",
    "        element = i\n",
    "        requested_var -= _var[i] # para ajuste do indice\n",
    "        break\n",
    "\n",
    "# repetindo o PCA com 80% da variância\n",
    "pca = doPCA(element) # element == 89 componentes\n",
    "_var = pca.explained_variance_ratio_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para 80% da variância é necessário manter 84 elementos. \n",
    "\n",
    "#### Vamos transformar os dados para fazer o KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com 89 elementos temos a variância requisitada.\n",
      "Formato dos dados com PCA (variância=80%): (1567, 89).\n",
      "As 89 componentes/colunas principais:\n",
      "[ 0.056  0.036  0.028  0.025  0.022  0.021  0.02   0.018  0.018  0.016\n",
      "  0.015  0.013  0.013  0.013  0.013  0.012  0.011  0.011  0.011  0.011\n",
      "  0.01   0.01   0.01   0.01   0.01   0.009  0.009  0.009  0.009  0.008\n",
      "  0.008  0.008  0.008  0.008  0.008  0.008  0.008  0.007  0.007  0.007\n",
      "  0.007  0.007  0.007  0.007  0.007  0.007  0.006  0.006  0.006  0.006\n",
      "  0.006  0.006  0.006  0.006  0.006  0.006  0.006  0.005  0.005  0.005\n",
      "  0.005  0.005  0.005  0.005  0.005  0.005  0.005  0.005  0.005  0.004\n",
      "  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004  0.004\n",
      "  0.004  0.004  0.004  0.003  0.003  0.003  0.003  0.003  0.003]\n",
      "\n",
      "A soma dessas componentes/colunas: 0.79580.\n"
     ]
    }
   ],
   "source": [
    "# dados transformados\n",
    "secom_PCA_80 = pca.transform(std_secom)\n",
    "\n",
    "# prints\n",
    "print('Com %d elementos temos a variância requisitada.' % (element))\n",
    "print('Formato dos dados com PCA (variância=80%): {}.'\\\n",
    "      .format(secom_PCA_80.shape))\n",
    "print('As %d componentes/colunas principais:' % (element))\n",
    "np.set_printoptions(precision=3)\n",
    "print(_var)\n",
    "print('\\nA soma dessas componentes/colunas: %.5f.' % np.sum(_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN com 5-fold externo e 3-fold interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em fold #1: o melhor k é: 11\n",
      "Acurácia do Fold = 85.98726114649682%\n",
      "Em fold #2: o melhor k é: 11\n",
      "Acurácia do Fold = 93.31210191082803%\n",
      "Em fold #3: o melhor k é: 11\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #4: o melhor k é: 11\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #5: o melhor k é: 11\n",
      "Acurácia do Fold = 94.56869009584665%\n",
      "\n",
      "Acurácia do Método: 93.36785983191224%\n"
     ]
    }
   ],
   "source": [
    "# acurácia inicial\n",
    "acc_knn = 0\n",
    "\n",
    "# separa os dados transformados  secom_PCA_80 em 5-fold\n",
    "kf_5 = KFold(n = len(labels), n_folds=5)\n",
    "\n",
    "#contador dos folds\n",
    "count = 0\n",
    "\n",
    "# para cada fold externo encontrar o melhor hiperparâmetro\n",
    "for train, test in kf_5:\n",
    "    count += 1\n",
    "    kf_3 = KFold(n = len(labels[train]), n_folds=3)\n",
    "    \n",
    "    # faz um grid search do melhor k em cada conjunto de treino do 5-fold\n",
    "    best_k, best_acc = 0,0\n",
    "        \n",
    "    for k in [1, 5, 11, 15, 21, 25]:\n",
    "        new_acc = 0\n",
    "        \n",
    "        for train_hp, test_hp in kf_3:\n",
    "            # define o knn            \n",
    "            knn = KNN(n_neighbors=k)\n",
    "            # treina secom_PCA_80\n",
    "            knn.fit(secom_PCA_80[train][train_hp], labels[train][train_hp]) \n",
    "            # avalia a acurária \n",
    "            new_acc += knn.score(secom_PCA_80[train][test_hp], labels[train][test_hp])\n",
    "        \n",
    "        # acurácia média do hiperparâmetro k\n",
    "        new_acc = new_acc/3\n",
    "        \n",
    "        # verifica se acurácia do hiperparametro k atual é a melhor\n",
    "        if (new_acc > best_acc):\n",
    "            best_acc = new_acc\n",
    "            best_k = k\n",
    "    \n",
    "    # imprime a melhor acurácia obtida pelo fold interno\n",
    "    print('Em fold #{}: o melhor k é: {}'.format(count, best_k))\n",
    "    \n",
    "    # ao fim do loop, calcula a acurácia para o melhor k\n",
    "    knn_out = KNN(n_neighbors=best_k)\n",
    "    \n",
    "    # treina com os valores do 5-fold externo\n",
    "    knn_out.fit(secom_PCA_80[train], labels[train]) \n",
    "    \n",
    "    # obtém a acurácia usando o conjunto de teste do 5-fold externo\n",
    "    print('Acurácia do Fold = {}%'.format(100*knn_out.score(secom_PCA_80[test],\\\n",
    "           labels[test])))\n",
    "   \n",
    "    # acha a acurácia média do método\n",
    "    acc_knn += knn_out.score(secom_PCA_80[test], labels[test])\n",
    "\n",
    "acc_knn /= 5    \n",
    "print('\\nAcurácia do Método: {}%'.format(acc_knn*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "### Para o SVM RBF teste para C=2**(-5), 2**(0), 2**(5), 2**(10) e gamma= 2**(-15) 2**(-10) 2**(-5) 2**(0) 2**(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 590)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_secom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em fold #1: o melhor c é: 0.031250 e gamma: 0.000031\n",
      "Acurácia do Fold = 85.98726114649682%\n",
      "Em fold #2: o melhor c é: 0.031250 e gamma: 0.000031\n",
      "Acurácia do Fold = 93.31210191082803%\n",
      "Em fold #3: o melhor c é: 0.031250 e gamma: 0.000031\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #4: o melhor c é: 0.031250 e gamma: 0.000031\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #5: o melhor c é: 0.031250 e gamma: 0.000031\n",
      "Acurácia do Fold = 94.56869009584665%\n",
      "\n",
      "Acurácia do Método: 93.36785983191224%\n"
     ]
    }
   ],
   "source": [
    "# acurácia inicial\n",
    "acc_svm = 0\n",
    "\n",
    "# separa os dados transformados  std_secom em 5-fold\n",
    "kf_5 = KFold(n = len(labels), n_folds=5)\n",
    "\n",
    "#contador dos folds\n",
    "count = 0\n",
    "\n",
    "# para cada fold externo encontrar o melhor hiperparâmetro\n",
    "for train, test in kf_5:\n",
    "    count += 1\n",
    "    kf_3 = KFold(n = len(labels[train]), n_folds=3)\n",
    "    \n",
    "    # faz um grid search do melhor k em cada conjunto de treino do 5-fold\n",
    "    best_c, best_gamma, best_acc = 0,0,0\n",
    "        \n",
    "    for c in [2**-5, 2**0, 2**5, 2**10]:\n",
    "        for gamma in [2**-15, 2**-10, 2**-5, 2**0, 2**5]:\n",
    "            new_acc = 0\n",
    "            for train_hp, test_hp in kf_3:\n",
    "                # define o SVM classificador svc\n",
    "                svc = SVC(C=c, kernel='rbf', gamma=gamma)\n",
    "                # treina std_secom\n",
    "                svc.fit(std_secom[train][train_hp], labels[train][train_hp]) \n",
    "                # avalia a acurária \n",
    "                new_acc += svc.score(std_secom[train][test_hp], \\\n",
    "                                     labels[train][test_hp])\n",
    "        \n",
    "            # acurácia média do hiperparâmetro k\n",
    "            new_acc = new_acc/3\n",
    "        \n",
    "            # verifica se acurácia do hiperparametro k atual é a melhor\n",
    "            if (new_acc > best_acc):\n",
    "                best_acc = new_acc\n",
    "                best_c = c\n",
    "                best_gamma = gamma\n",
    "    \n",
    "    # imprime a melhor acurácia obtida pelo fold interno\n",
    "    print('Em fold #%d: o melhor c é: %.6f e gamma: %.6f'\n",
    "           % (count, best_c, best_gamma))\n",
    "    \n",
    "    # ao fim do loop, calcula a acurácia para o melhor c e gamma\n",
    "    svc_out = SVC(C=best_c, kernel='rbf', gamma=best_gamma)\n",
    "    \n",
    "    # treina com os valores do 5-fold externo\n",
    "    svc_out.fit(std_secom[train], labels[train]) \n",
    "    \n",
    "    # obtém a acurácia usando o conjunto de teste do 5-fold externo\n",
    "    print('Acurácia do Fold = {}%'.format(100*svc_out.score(std_secom[test],\\\n",
    "           labels[test])))\n",
    "   \n",
    "    # acha a acurácia média do método\n",
    "    acc_svm += svc_out.score(std_secom[test], labels[test])\n",
    "\n",
    "acc_svm /= 5    \n",
    "print('\\nAcurácia do Método: {}%'.format(acc_svm*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural\n",
    "###  Para a rede neural, teste com 10, 20, 30 e 40 neuronios na camada escondida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em fold #1: o melhor número de neurônios na camada escondida é: 20\n",
      "Acurácia do Fold = 76.75159235668791%\n",
      "Em fold #2: o melhor número de neurônios na camada escondida é: 40\n",
      "Acurácia do Fold = 90.76433121019109%\n",
      "Em fold #3: o melhor número de neurônios na camada escondida é: 30\n",
      "Acurácia do Fold = 94.56869009584665%\n",
      "Em fold #4: o melhor número de neurônios na camada escondida é: 30\n",
      "Acurácia do Fold = 94.56869009584665%\n",
      "Em fold #5: o melhor número de neurônios na camada escondida é: 40\n",
      "Acurácia do Fold = 93.9297124600639%\n",
      "\n",
      "Acurácia do Método: 90.11660324372724%\n"
     ]
    }
   ],
   "source": [
    "# acurácia inicial\n",
    "acc = 0\n",
    "\n",
    "# separa os dados transformados  std_secom em 5-fold\n",
    "kf_5 = KFold(n = len(labels), n_folds=5)\n",
    "\n",
    "#contador dos folds\n",
    "count = 0\n",
    "\n",
    "# para cada fold externo encontrar o melhor hiperparâmetro\n",
    "for train, test in kf_5:\n",
    "    count += 1\n",
    "    kf_3 = KFold(n = len(labels[train]), n_folds=3)\n",
    "    \n",
    "    # faz um grid search do melhor k em cada conjunto de treino do 5-fold\n",
    "    best_neur, best_acc = 0,0\n",
    "        \n",
    "    for neur in [10, 20, 30, 40]:\n",
    "        new_acc = 0\n",
    "        \n",
    "        for train_hp, test_hp in kf_3:\n",
    "            # define o knn            \n",
    "            nn = MLP(solver='lbfgs', alpha=1, hidden_layer_sizes=neur, random_state=1)\n",
    "            # treina std_secom\n",
    "            nn.fit(std_secom[train][train_hp], labels[train][train_hp]) \n",
    "            # avalia a acurária \n",
    "            new_acc += nn.score(std_secom[train][test_hp], labels[train][test_hp])\n",
    "        \n",
    "        # acurácia média do hiperparâmetro k\n",
    "        new_acc = new_acc/3\n",
    "        \n",
    "        # verifica se acurácia do hiperparametro k atual é a melhor\n",
    "        if (new_acc > best_acc):\n",
    "            best_acc = new_acc\n",
    "            best_neur = neur\n",
    "    \n",
    "    # imprime a melhor acurácia obtida pelo fold interno\n",
    "    print('Em fold #{}: o melhor número de neurônios na camada escondida é: {}'.format(count, best_neur))\n",
    "    \n",
    "    # ao fim do loop, calcula a acurácia para o melhor k\n",
    "    nn_out = MLP(solver='lbfgs', alpha=1, hidden_layer_sizes=best_neur, random_state=1)\n",
    "    \n",
    "    # treina com os valores do 5-fold externo\n",
    "    nn_out.fit(std_secom[train], labels[train]) \n",
    "    \n",
    "    # obtém a acurácia usando o conjunto de teste do 5-fold externo\n",
    "    print('Acurácia do Fold = {}%'.format(100*nn_out.score(std_secom[test],\\\n",
    "           labels[test])))\n",
    "   \n",
    "    # acha a acurácia média do método\n",
    "    acc += nn_out.score(std_secom[test], labels[test])\n",
    "\n",
    "acc /= 5    \n",
    "print('\\nAcurácia do Método: {}%'.format(acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest \n",
    "\n",
    "### Para o RF, teste com n_featrues = 10, 15, 20, 25 e ntrees = 100, 200, 300 e 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em fold #1: o melhor n_feature é: 10 e n_tree: 400\n",
      "Acurácia do Fold = 85.98726114649682%\n",
      "Em fold #2: o melhor n_feature é: 25 e n_tree: 100\n",
      "Acurácia do Fold = 93.31210191082803%\n",
      "Em fold #3: o melhor n_feature é: 15 e n_tree: 200\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #4: o melhor n_feature é: 10 e n_tree: 100\n",
      "Acurácia do Fold = 96.1661341853035%\n",
      "Em fold #5: o melhor n_feature é: 20 e n_tree: 100\n",
      "Acurácia do Fold = 94.56869009584665%\n",
      "\n",
      "Acurácia do Método: 93.30396206833397%\n"
     ]
    }
   ],
   "source": [
    "# acurácia inicial\n",
    "acc = 0\n",
    "\n",
    "# separa os dados transformados  std_secom em 5-fold\n",
    "kf_5 = KFold(n = len(labels), n_folds=5)\n",
    "\n",
    "#contador dos folds\n",
    "count = 0\n",
    "\n",
    "# para cada fold externo encontrar o melhor hiperparâmetro\n",
    "for train, test in kf_5:\n",
    "    count += 1\n",
    "    kf_3 = KFold(n = len(labels[train]), n_folds=3)\n",
    "    \n",
    "    # faz um grid search do melhor k em cada conjunto de treino do 5-fold\n",
    "    best_n_features, best_n_features, best_acc = 0,0,0\n",
    "        \n",
    "    for n_features in [10, 15, 20, 25]:\n",
    "        for n_trees in [100, 200, 300, 400]:\n",
    "            new_acc = 0\n",
    "            for train_hp, test_hp in kf_3:\n",
    "                # define o SVM classificador svc\n",
    "                rf = RF(max_depth=n_trees, n_estimators=n_features)\n",
    "                # treina std_secom\n",
    "                rf.fit(std_secom[train][train_hp], labels[train][train_hp]) \n",
    "                # avalia a acurária \n",
    "                new_acc += rf.score(std_secom[train][test_hp], \\\n",
    "                                     labels[train][test_hp])\n",
    "        \n",
    "            # acurácia média do hiperparâmetro k\n",
    "            new_acc = new_acc/3\n",
    "        \n",
    "            # verifica se acurácia do hiperparametro k atual é a melhor\n",
    "            if (new_acc > best_acc):\n",
    "                best_acc        = new_acc\n",
    "                best_n_features = n_features\n",
    "                best_n_trees    = n_trees\n",
    "    \n",
    "    # imprime a melhor acurácia obtida pelo fold interno\n",
    "    print('Em fold #%d: o melhor n_feature é: %d e n_tree: %d'\n",
    "           % (count, best_n_features, best_n_trees))\n",
    "    \n",
    "    # ao fim do loop, calcula a acurácia para o melhor c e gamma\n",
    "    rf_out = RF(max_features=best_n_features, max_depth=best_n_trees)\n",
    "    \n",
    "    # treina com os valores do 5-fold externo\n",
    "    rf_out.fit(std_secom[train], labels[train]) \n",
    "    \n",
    "    # obtém a acurácia usando o conjunto de teste do 5-fold externo\n",
    "    print('Acurácia do Fold = {}%'.format(100*rf_out.score(std_secom[test],\\\n",
    "           labels[test])))\n",
    "   \n",
    "    # acha a acurácia média do método\n",
    "    acc += rf_out.score(std_secom[test], labels[test])\n",
    "\n",
    "acc /= 5    \n",
    "print('\\nAcurácia do Método: {}%'.format(acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machine\n",
    "### Para o GBM (ou XGB) teste para numero de arvores = 30, 70, e 100, com learning rate de 0.1 e 0.05, e profundidade da arvore=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em fold #1: o melhor learning rate é: 0.10 e n_tree: 100\n",
      "Acurácia do Fold = 71.97452229299363%\n",
      "Em fold #2: o melhor learning rate é: 0.10 e n_tree: 70\n",
      "Acurácia do Fold = 92.35668789808918%\n",
      "Em fold #3: o melhor learning rate é: 0.10 e n_tree: 70\n",
      "Acurácia do Fold = 94.88817891373802%\n",
      "Em fold #4: o melhor learning rate é: 0.05 e n_tree: 30\n",
      "Acurácia do Fold = 96.48562300319489%\n",
      "Em fold #5: o melhor learning rate é: 0.10 e n_tree: 70\n",
      "Acurácia do Fold = 93.9297124600639%\n",
      "\n",
      "Acurácia do Método: 89.92694491361594%\n"
     ]
    }
   ],
   "source": [
    "# acurácia inicial\n",
    "acc = 0\n",
    "\n",
    "# separa os dados transformados  std_secom em 5-fold\n",
    "kf_5 = KFold(n = len(labels), n_folds=5)\n",
    "\n",
    "#contador dos folds\n",
    "count = 0\n",
    "\n",
    "# para cada fold externo encontrar o melhor hiperparâmetro\n",
    "for train, test in kf_5:\n",
    "    count += 1\n",
    "    kf_3 = KFold(n = len(labels[train]), n_folds=3)\n",
    "    \n",
    "    # faz um grid search do melhor k em cada conjunto de treino do 5-fold\n",
    "    best_learning_rate, best_n_tree, best_acc = 0.1,0,0\n",
    "        \n",
    "    for ln in [0.1, 0.05]:\n",
    "        for n_trees in [30, 70, 100]:\n",
    "            new_acc = 0\n",
    "            for train_hp, test_hp in kf_3:\n",
    "                # define o GBM classificador \n",
    "                gbm = GBM(n_estimators=n_trees, learning_rate=ln, max_depth=5)\n",
    "                # treina std_secom\n",
    "                rf.fit(std_secom[train][train_hp], labels[train][train_hp]) \n",
    "                # avalia a acurária \n",
    "                new_acc += rf.score(std_secom[train][test_hp], \\\n",
    "                                     labels[train][test_hp])\n",
    "        \n",
    "            # acurácia média do hiperparâmetro k\n",
    "            new_acc = new_acc/3\n",
    "        \n",
    "            # verifica se acurácia do hiperparametro k atual é a melhor\n",
    "            if (new_acc > best_acc):\n",
    "                best_acc        = new_acc\n",
    "                best_learning_rate = ln\n",
    "                best_n_tree    = n_trees\n",
    "    \n",
    "    # imprime a melhor acurácia obtida pelo fold interno\n",
    "    print('Em fold #%d: o melhor learning rate é: %0.2f e n_tree: %d'\n",
    "           % (count, best_learning_rate, best_n_tree))\n",
    "    \n",
    "    # ao fim do loop, calcula a acurácia para o melhor c e gamma\n",
    "    gbm_out = GBM(n_estimators=best_n_tree, learning_rate=best_learning_rate)\n",
    "    \n",
    "    # treina com os valores do 5-fold externo\n",
    "    gbm_out.fit(std_secom[train], labels[train]) \n",
    "    \n",
    "    # obtém a acurácia usando o conjunto de teste do 5-fold externo\n",
    "    print('Acurácia do Fold = {}%'.format(100*gbm_out.score(std_secom[test],\\\n",
    "           labels[test])))\n",
    "   \n",
    "    # acha a acurácia média do método\n",
    "    acc += gbm_out.score(std_secom[test], labels[test])\n",
    "\n",
    "acc /= 5    \n",
    "print('\\nAcurácia do Método: {}%'.format(acc*100))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [PYT3]",
   "language": "python",
   "name": "Python [PYT3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
